{
 "cells": [
  {
   "cell_type": "raw",
   "id": "779f0669",
   "metadata": {},
   "source": [
    "---\n",
    "title: Exploring and explaining undocumented APIs with ChatGPT and LangChain\n",
    "description: How much documentation is enough when using an undocumented and unofficial REST API?\n",
    "date: 2023-04-09\n",
    "author: Jonathan Soma\n",
    "published: true\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf22a525",
   "metadata": {},
   "source": [
    "Hi, I'm Soma! You can find me on email at [jonathan.soma@gmail.com](mailto:jonathan.soma@gmail.com), on Twitter at [@dangerscarf](https://twitter.com/dangerscarf), or maybe even on [this newsletter I've never sent](https://tinyletter.com/jsoma)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b32eb",
   "metadata": {},
   "source": [
    "# The secret world of undocumented APIs\n",
    "\n",
    "While scraping a website is all good and fun, sometimes there's a better/faster/cheaper way to get your data: **undocumented APIs!**\n",
    "\n",
    "An API is how two computers talk to each other without the ugliness of the web getting involved. To be overly simplistic, instead of browsing a site like a normal human being, your computer visits a special URL to search or download data in bulk. For example, Twitter's API is how researchers got millions and millions of tweets before Musk locked 'em all out.\n",
    "\n",
    "While many APIs are public-facing and advertised, some are semi-secret or unofficial. For example, when you visit [Pitchfork](https://pitchfork.com) and search for music reviews, your browser secretly visits [this URL](https://pitchfork.com/api/v2/search/?genre=experimental&genre=global&genre=jazz&genre=metal&genre=pop&genre=rap&genre=rock&types=reviews&sort=publishdate%20desc%2Cposition%20asc&size=5&start=0&rating_from=0.0) to find the data that it eventually displays on the page. That listing of data – the API \"endpoint\" – is all about computers reading it, not people, so it looks awful and ugly and very much like this:\n",
    "\n",
    "```python\n",
    "{\"count\":10000,\"previous\":null,\"next\":null,\"results\":{\"category\":null,\"list\":[{\"dek\":\"<p>The pop trio’s new single casts the iconic 24-hour breakfast chain as a place of conversation and healing, not fights and thrown chairs.</p>\\n\",\"seoDescription\":\"The pop trio’s new single casts the iconic 24-hour breakfast chain as a place of conversation and healing, not fights and thrown chairs.\",\"promoDescription\":\"<p>The pop trio’s new single casts the iconic 24-hour breakfast chain as a place of conversation and healing, not fights and thrown chairs.</p>\\n\",\"socialDescription\":\"The pop trio’s new single casts the iconic 24-hour breakfast chain as a place of conversation and healing, not fights and thrown chairs.\",\"authors\":[{\"id\":\"592604b57fd06e5349102f43\",\"name\":\"Evan Minsker\",\"title\":\"Associate News Director\",\"url\":\"/staff/evan-minsker/\",\"slug\":\"staff/evan-minsker\"}]\n",
    "```\n",
    "\n",
    "Horrifying, right? In this tutorial, we'll be looking at three things:\n",
    "\n",
    "1. Exploring how LangChain talks to APIs\n",
    "2. Using ChatGPT to document previously-undocumented APIs\n",
    "3. Comparing two techniques for enabling LangChain to use undocumented APIs (explicit vs implicit documentation)\n",
    "\n",
    "By the end we'll have developed a tool that can use the unofficial Pitchfork API to answer natural-language questions about albums they've reviewed.\n",
    "\n",
    "::: {.callout-note appearance='simple'}\n",
    "\n",
    "Want to learn how to discover undocumented APIs? Check out [Inspect Element](https://inspectelement.org/apis.html) by [Leon Yin](https://twitter.com/leonYin/)!\n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "Give me one moment to set things up! First we'll pull in all of our API keys using [python-dotenv](https://pypi.org/project/python-dotenv/), then we'll use a thousand and one imports to bring in LangChain and friends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e64d5369",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b447b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain imports\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import APIChain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain import LLMChain\n",
    "\n",
    "# Normal human imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68192b59",
   "metadata": {},
   "source": [
    "Even though GPT-4 is out, we'll be using GPT-3.5-turbo for this one. At the moment it's infinitely cheaper, and every penny matters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f7d75d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1954aa87",
   "metadata": {},
   "source": [
    "# LangChain and documented APIs\n",
    "\n",
    "[LangChain](https://python.langchain.com) is a \"framework for developing applications powered by language models,\" which really undersells the fact that it's a universe-altering suite of tools for putting GPT (and related tools) to work. In this tutorial we're focusing on how it **interacts with APIs.**\n",
    "\n",
    "In the [LangChain documentation for working with APIs](https://python.langchain.com/en/latest/modules/chains/examples/api.html) there's a super-simple example of using `APIChain` to get an answer from a [free weather API](https://open-meteo.com/). You create your API-aware \"chain\" from two things: your large language model (in this case, GPT-3.5-turbo) and the documentation to the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d1a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = APIChain.from_llm_and_api_docs(llm, open_meteo_docs.OPEN_METEO_DOCS, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35025719",
   "metadata": {},
   "source": [
    "Once your chain is created, you ask it your question and the chain goes to work sending information back and forth with ChatGPT:\n",
    "\n",
    "1. The chain sends the API docs to ChatGPT, asking what API URL you should visit\n",
    "2. ChatGPT reads the docs, sends back a URL\n",
    "2. LangChain obtains the data from the URL\n",
    "3. The data is sent back to ChatGPT, which uses it to answer your question\n",
    "\n",
    "Let's see it in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e58375da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new APIChain chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mhttps://api.open-meteo.com/v1/forecast?latitude=48.137154&longitude=11.576124&current_weather=true&temperature_unit=fahrenheit\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m{\"latitude\":48.14,\"longitude\":11.58,\"generationtime_ms\":0.15795230865478516,\"utc_offset_seconds\":0,\"timezone\":\"GMT\",\"timezone_abbreviation\":\"GMT\",\"elevation\":526.0,\"current_weather\":{\"temperature\":40.2,\"windspeed\":8.8,\"winddirection\":261.0,\"weathercode\":2,\"is_day\":0,\"time\":\"2023-04-08T00:00\"}}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current weather in Munich, Germany is 40.2 degrees Fahrenheit.'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run('What is the weather like right now in Munich, Germany in degrees Farenheit?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def89563",
   "metadata": {},
   "source": [
    "You can see each step of the process: the URL, the data, the answer! This transparency is thanks to us using `verbose=True` when we first created the chain.\n",
    "\n",
    "The \"secret sauce\" of the `APIChain` formula is the OpenMeteo API documentation. The documentation is detailed enough to provide ChatGPT with everything it needs to know in creating the API URL: from what I can see, it needs a latitude and longitude, a `current_weather=true`, and a demand to be in degrees fahrenheit.\n",
    "\n",
    "How detailed is the OpenMeteo documentation that ChatGPT is using? It's easy enough to examine the documentation for this particular API, as it's actually provided as part of LangChain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "03cf9f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE URL: https://api.open-meteo.com/\n",
      "\n",
      "API Documentation\n",
      "The API endpoint /v1/forecast accepts a geographical coordinate, a list of weather variables and responds with a JSON hourly weather forecast for 7 days. Time always starts at 0:00 today and contains 168 hours. All URL parameters are listed below:\n",
      "\n",
      "Parameter\tFormat\tRequired\tDefault\tDescription\n",
      "latitude, longitude\tFloating point\tYes\t\tGeographical WGS84 coordinate of the location\n",
      "hourly\tString array\tNo\t\tA list of weather variables which should be returned. Values can be comma separated, or multiple &hourly= parameter in the URL can be used.\n",
      "daily\tString array\tNo\t\tA list of daily weather variable aggregations which should be returned. Values can be comma separated, or multiple &daily= parameter in the URL can be used. If daily weather variables are specified, parameter timezone is required.\n",
      "current_weather\tBool\tNo\tfalse\tInclude current weather conditions in the JSON output.\n",
      "temperature_unit\tString\tNo\tcelsius\tIf fahrenheit is set, all temperature values are converted to Fahrenheit.\n",
      "windspeed_unit\tString\tNo\tkmh\tOther wind speed speed units: ms, mph and kn\n",
      "precipitation_unit\tString\tNo\tmm\tOther precipitation amount units: inch\n",
      "timeformat\tString\tNo\tiso8601\tIf format unixtime is selected, all time values are returned in UNIX epoch time in seconds. Please note that all timestamp are in GMT+0! For daily values with unix timestamps, please apply utc_offset_seconds again to get the correct date.\n",
      "timezone\tString\tNo\tGMT\tIf timezone is set, all timestamps are returned as local-time and data is returned starting at 00:00 local-time. Any time zone name from the time zone database is supported. If auto is set as a time zone, the coordinates will be automatically resolved to the local time zone.\n",
      "past_days\tInteger (0-2)\tNo\t0\tIf past_days is set, yesterday or the day before yesterday data are also returned.\n",
      "start_date\n",
      "end_date\tString (yyyy-mm-dd)\tNo\t\tThe time interval to get weather data. A day must be specified as an ISO8601 date (e.g. 2022-06-30).\n",
      "models\tString array\tNo\tauto\tManually select one or more weather models. Per default, the best suitable weather models will be combined.\n",
      "\n",
      "Hourly Parameter Definition\n",
      "The parameter &hourly= accepts the following values. Most weather variables are given as an instantaneous value for the indicated hour. Some variables like precipitation are calculated from the preceding hour as an average or sum.\n",
      "\n",
      "Variable\tValid time\tUnit\tDescription\n",
      "temperature_2m\tInstant\t°C (°F)\tAir temperature at 2 meters above ground\n",
      "snowfall\tPreceding hour sum\tcm (inch)\tSnowfall amount of the preceding hour in centimeters. For the water equivalent in millimeter, divide by 7. E.g. 7 cm snow = 10 mm precipitation water equivalent\n",
      "rain\tPreceding hour sum\tmm (inch)\tRain from large scale weather systems of the preceding hour in millimeter\n",
      "showers\tPreceding hour sum\tmm (inch)\tShowers from convective precipitation in millimeters from the preceding hour\n",
      "weathercode\tInstant\tWMO code\tWeather condition as a numeric code. Follow WMO weather interpretation codes. See table below for details.\n",
      "snow_depth\tInstant\tmeters\tSnow depth on the ground\n",
      "freezinglevel_height\tInstant\tmeters\tAltitude above sea level of the 0°C level\n",
      "visibility\tInstant\tmeters\tViewing distance in meters. Influenced by low clouds, humidity and aerosols. Maximum visibility is approximately 24 km.\n"
     ]
    }
   ],
   "source": [
    "print(open_meteo_docs.OPEN_METEO_DOCS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60bfd3d",
   "metadata": {},
   "source": [
    "Look at all those details and options! It might be overwhelming to us, but ChatGPT has no problem figuring it out.\n",
    "\n",
    "If we want to use the [Pitchfork API](https://pitchfork.com/api/v2/search/?genre=experimental&genre=global&genre=jazz&genre=metal&genre=pop&genre=rap&genre=rock&types=reviews&sort=publishdate%20desc%2Cposition%20asc&size=5&start=0&rating_from=0.0) to ask questions in a similar fashion, it seems like we might need some documentation for it.\n",
    "\n",
    "There's only one problem: **it's an unofficial, undocumented API.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66250598",
   "metadata": {},
   "source": [
    "# Automatic documentation generation\n",
    "\n",
    "Luckily for us, APIs aren't (often) all that complicated. Let's look at the Pitchfork API's URL:\n",
    "\n",
    "```\n",
    "https://pitchfork.com/api/v2/search/?genre=experimental&genre=global&genre=jazz&genre=metal&genre=pop&genre=rap&genre=rock&types=reviews&sort=publishdate%20desc%2Cposition%20asc&size=5&start=0&rating_from=0.0\n",
    "```\n",
    "\n",
    "After the `/search/` part, we see a lot of things we can making assumptions about.\n",
    "\n",
    "* `size=5` probably has to do with how many results are returned. In this case, our search gives us 5 results.\n",
    "* `genre=jazz&genre=metal` is probably all of the genres of albums to return\n",
    "* `rating_from=0.0` potentially sets a lower bar for the rating of the album reviews. Pitchfork ranks them 0-10, so this includes all albums.\n",
    "* There's also `types`, `sort`, `start`... We can guess about those, too!\n",
    "\n",
    "Do we know that our guesses are correct? Absolutely not. But with a little time and some manual labor, we might be able to test our hypotheses about what each parameter actually means!\n",
    "\n",
    "But we have neither time or manual labor: we're playing loose and fast with the truth, we're moving fast and breaking things, we're fucking around and hopefully only finding out beautiful, blissful things. Instead, we have AI.\n",
    "\n",
    "Let's just irresponsibly ask ChatGPT to make all of those assumptions for us, and write some nice beautiful documentation just like the OpenMeteo ones!\n",
    "\n",
    "Down below we build a prompt that takes an API url and asks ChatGPT to write us \"detailed documentation\" for the provided URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ef7183ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"api_url\"],\n",
    "    template=\"\"\"Act as a technical writer. Write detailed documentation for the API that exists at {api_url}. Only detail the request, do not describe the response. Do not include any parameters not in the sample endpoint.\"\"\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c932d31",
   "metadata": {},
   "source": [
    "The code is slightly more complicated than I'd like, as a few weeks ago LangChain decided that chat-based LLMs like GPT-3.5 needed to be talked to with prompts instead of just saying `llm.run`. I'm sorry it's a little verbose, but we'll both survive.\n",
    "\n",
    "Notice my extra-stern warning to not provide an example response. While we're fine with ChatGPT inventing how to use it, we'd rather not have it waste time inventing data that comes back from the API exactly looks like.\n",
    "\n",
    "Now we'll take our Pitchfork API url and feed it into the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f1a712ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAct as a technical writer. Write detailed documentation for the API that exists at https://pitchfork.com/api/v2/search/?genre=experimental&genre=global&genre=jazz&genre=metal&genre=pop&genre=rap&genre=rock&types=reviews&sort=publishdate%20desc%2Cposition%20asc&size=5&start=0&rating_from=0.0. Only detail the request, do not describe the response. Do not include any parameters not in the sample endpoint.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "API Documentation\n",
      "\n",
      "Pitchfork Search API\n",
      "\n",
      "This API is used to search for reviews on Pitchfork based on specified genres, types, sorting, and size.\n",
      "\n",
      "Sample Endpoint:\n",
      "\n",
      "https://pitchfork.com/api/v2/search/?genre=experimental&genre=global&genre=jazz&genre=metal&genre=pop&genre=rap&genre=rock&types=reviews&sort=publishdate%20desc%2Cposition%20asc&size=5&start=0&rating_from=0.0\n",
      "\n",
      "Request Method: GET\n",
      "\n",
      "Request Parameters:\n",
      "\n",
      "• genre: This parameter is used to specify the genre of the review. You can specify multiple genres by adding the parameter multiple times. Possible values are experimental, global, jazz, metal, pop, rap, and rock.\n",
      "\n",
      "• types: This parameter is used to specify the type of the content you want to retrieve. The possible values are reviews, features, tracks, labels, and artists.\n",
      "\n",
      "• sort: This parameter is used to specify the sorting order of the content you want to retrieve. The possible values are publishdate desc, publishdate asc, position desc, and position asc. You can specify multiple sorting orders by separating them with commas.\n",
      "\n",
      "• size: This parameter is used to specify the number of results that you want to retrieve. The possible values are integers between 1 and 100.\n",
      "\n",
      "• start: This parameter is used to specify the starting position for the search, to retrieve the next \"page\" of results. The possible values are integers greater than or equal to 0.\n",
      "\n",
      "• rating_from: This parameter is used to specify the minimum rating for the content you want to retrieve. The possible values are decimal numbers between 0.0 and 10.0.\n",
      "\n",
      "Response Format:\n",
      "\n",
      "The response format for this API is in JSON.\n",
      "\n",
      "Authentication:\n",
      "\n",
      "No authentication is required to use this API.\n",
      "\n",
      "Error Codes:\n",
      "\n",
      "The following response codes may be returned by the API:\n",
      "\n",
      "• 200 OK: Successful request.\n",
      "• 400 Bad Request: Invalid parameters.\n",
      "• 401 Unauthorized: Authentication required.\n",
      "• 403 Forbidden: Access denied.\n",
      "• 404 Not Found: Resource not found.\n",
      "• 500 Internal Server Error: Server error.\n",
      "\n",
      "Limitations:\n",
      "\n",
      "• This API is subject to rate limiting.\n",
      "• The maximum size of a search result is 100.\n",
      "• Some parameters may not be compatible with each other - for example, using both sorting and start parameters may lead to unexpected behavior.\n",
      "\n",
      "Examples:\n",
      "\n",
      "To retrieve the 5 most recent reviews for the experimental, jazz, and pop genres, the request URL would be:\n",
      "\n",
      "https://pitchfork.com/api/v2/search/?genre=experimental&genre=jazz&genre=pop&types=reviews&sort=publishdate%20desc%2Cposition%20asc&size=5&start=0&rating_from=0.0\n",
      "\n",
      "To retrieve the top 5 highest-rated metal reviews, the request URL would be:\n",
      "\n",
      "https://pitchfork.com/api/v2/search/?genre=metal&types=reviews&sort=position%20asc&size=5&start=0&rating_from=8.0\n",
      "\n",
      "To retrieve the next 5 results from a previous query, the request URL would be:\n",
      "\n",
      "https://pitchfork.com/api/v2/search/?genre=experimental&genre=jazz&genre=pop&types=reviews&sort=publishdate%20desc%2Cposition%20asc&size=5&start=5&rating_from=0.0\n"
     ]
    }
   ],
   "source": [
    "url = \"https://pitchfork.com/api/v2/search/?genre=experimental&genre=global&genre=jazz&genre=metal&genre=pop&genre=rap&genre=rock&types=reviews&sort=publishdate%20desc%2Cposition%20asc&size=5&start=0&rating_from=0.0\"\n",
    "\n",
    "response = chain.run(url)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3814f825",
   "metadata": {},
   "source": [
    "That documentation is far nicer than anything I'd personally write!\n",
    "\n",
    "Is it all correct? **We have no idea!** But to continue thinking positively: if we found a bug we can always make manual edits.\n",
    "\n",
    "Now let's talk about how we want to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd26c32",
   "metadata": {},
   "source": [
    "# Explicit documentation\n",
    "\n",
    "I'm going to call the type of text above **explicit documentation**. It's \"real\" documentation, words phrased and formatted in order to communicate specific details about and examples of the API.\n",
    "\n",
    "This explicit documentation is just like the OpenMeteo documentation from the LangChain documentation, and we're going to use it in the exact same way. We'll make a new `APIChain`, giving it the language model and the API docs.\n",
    "\n",
    "After the chain is made, we'll ask it our question: it should use the documentation to format a URL, then use the data from the URL to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "802550c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the response from above as `explicit_docs`, to use later\n",
    "explicit_docs = response\n",
    "explicit_chain = APIChain.from_llm_and_api_docs(llm, explicit_docs, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5d4f04d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new APIChain chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mhttps://pitchfork.com/api/v2/search/?genre=rap&types=reviews&sort=publishdate%20asc&size=1&rating_from=0.0\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m{\"count\":4253,\"previous\":null,\"next\":null,\"results\":{\"category\":null,\"list\":[{\"tombstone\":{\"bnm\":false,\"bnr\":false,\"albums\":[{\"id\":\"5929c3a7eb335119a49ed773\",\"album\":{\"artists\":[{\"id\":\"592994259d034d5c69bf1739\",\"display_name\":\"Roots Manuva\",\"url\":\"/artists/2672-roots-manuva/\",\"genres\":[{\"display_name\":\"Electronic\",\"slug\":\"electronic\"},{\"display_name\":\"Jazz\",\"slug\":\"jazz\"},{\"display_name\":\"Rap\",\"slug\":\"rap\"}],\"slug\":\"592994259d034d5c69bf1739\",\"photos\":{\"tout\":{\"width\":300,\"height\":300,\"credit\":\"\",\"caption\":\"\",\"altText\":\"Image may contain: Face, Human, Person, Roots Manuva, Head, Photo, Portrait, and Photography\",\"modelName\":\"photo\",\"title\":\"Roots Manuva artist image\",\"sizes\":{\"sm\":\"https://media.pitchfork.com/photos/59299426c0084474cd0bec29/1:1/w_150/3d81e0d6.jpg\",\"m\":\"https://media.pitchfork.com/photos/59299426c0084474cd0bec29/1:1/w_300/3d81e0d6.jpg\"}},\"lede\":false,\"social\":false}}],\"display_name\":\"Brand New Secondhand\",\"labels\":[{\"id\":\"592608737fd06e5349102fdb\",\"name\":\"Ninja Tune\",\"display_name\":\"Ninja Tune\"},{\"id\":\"59260899c31f3f3472b1d6cc\",\"name\":\"Big Dada\",\"display_name\":\"Big Dada\"}],\"release_year\":1999,\"photos\":{\"tout\":{\"width\":150,\"height\":150,\"credit\":\"\",\"caption\":\"\",\"altText\":\"Image may contain: Display, Screen, Electronics, Monitor, Television, and TV\",\"title\":\"Brand New Secondhand cover art\",\"sizes\":{\"list\":\"https://media.pitchfork.com/photos/5929c3a7c0084474cd0c3506/1:1/w_160/c23e052b.gif\",\"standard\":\"https://media.pitchfork.com/photos/5929c3a7c0084474cd0c3506/1:1/w_600/c23e052b.gif\",\"homepageSmall\":\"https://media.pitchfork.com/photos/5929c3a7c0084474cd0c3506/1:1/w_55/c23e052b.gif\",\"homepageLarge\":\"https://media.pitchfork.com/photos/5929c3a7c0084474cd0c3506/1:1/w_320/c23e052b.gif\"}},\"lede\":false,\"social\":false}},\"rating\":{\"display_rating\":\"9.5\",\"rating\":\"9.5\",\"bnm\":false,\"bnr\":false},\"labels_and_years\":[{\"labels\":[{\"id\":\"592608737fd06e5349102fdb\",\"name\":\"Ninja Tune\",\"display_name\":\"Ninja Tune\"},{\"id\":\"59260899c31f3f3472b1d6cc\",\"name\":\"Big Dada\",\"display_name\":\"Big Dada\"}],\"year\":1999}]}]},\"artists\":[{\"id\":\"592994259d034d5c69bf1739\",\"display_name\":\"Roots Manuva\",\"url\":\"/artists/2672-roots-manuva/\",\"genres\":[{\"display_name\":\"Electronic\",\"slug\":\"electronic\"},{\"display_name\":\"Jazz\",\"slug\":\"jazz\"},{\"display_name\":\"Rap\",\"slug\":\"rap\"}],\"slug\":\"592994259d034d5c69bf1739\",\"photos\":{\"tout\":{\"width\":300,\"height\":300,\"credit\":\"\",\"caption\":\"\",\"altText\":\"Image may contain: Face, Human, Person, Roots Manuva, Head, Photo, Portrait, and Photography\",\"modelName\":\"photo\",\"title\":\"Roots Manuva artist image\",\"sizes\":{\"sm\":\"https://media.pitchfork.com/photos/59299426c0084474cd0bec29/1:1/w_150/3d81e0d6.jpg\",\"m\":\"https://media.pitchfork.com/photos/59299426c0084474cd0bec29/1:1/w_300/3d81e0d6.jpg\"}},\"lede\":false,\"social\":false}}],\"genres\":[{\"display_name\":\"Electronic\",\"slug\":\"electronic\"},{\"display_name\":\"Jazz\",\"slug\":\"jazz\"},{\"display_name\":\"Rap\",\"slug\":\"rap\"}],\"channel\":\"\",\"subChannel\":\"\",\"position\":6,\"id\":\"5929e2b6c0084474cd0c4dc2\",\"url\":\"/reviews/albums/5099-brand-new-secondhand/\",\"contentType\":\"albumreview\",\"title\":\"<em>Brand New Secondhand</em>\",\"seoTitle\":\"Brand New Secondhand\",\"socialTitle\":\"Roots Manuva: Brand New Secondhand\",\"promoTitle\":\"Brand New Secondhand\",\"authors\":[{\"id\":\"592604af17cea934e4daf5f4\",\"name\":\"Paul Cooper\",\"title\":\"Contributor\",\"url\":\"/staff/paul-cooper/\",\"slug\":\"staff/paul-cooper\"}],\"pubDate\":\"1999-03-23T06:00:06.000Z\",\"timestamp\":922168806000,\"modifiedAt\":\"2022-03-31T08:47:24.426Z\",\"dek\":\"<p>For politcially unaware, socially unconscious, ethically moribund pop culture vultures, there's no bigger disappointment than UK hip-hop. In the ...</p>\\n\",\"seoDescription\":\"For politcially unaware, socially unconscious, ethically moribund pop culture vultures, there's no bigger disappointment than UK hip-hop. In the ...\",\"promoDescription\":\"<p>For politcially unaware, socially unconscious, ethically moribund pop culture vultures, there's no bigger disappointment than UK hip-hop. In the ...</p>\\n\",\"socialDescription\":\"For politcially unaware, socially unconscious, ethically moribund pop culture vultures, there's no bigger disappointment than UK hip-hop. In the ...\",\"privateTags\":[\"_dj_id:5099\",\"_original_author_id:95\"],\"tags\":[]}]}}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The first rap album reviewed by Pitchfork was \"Brand New Secondhand\" by Roots Manuva, with a rating of 9.5. The review was published on March 23, 1999.\n"
     ]
    }
   ],
   "source": [
    "response = explicit_chain.run(\"What was the first rap album reviewed by pitchfork?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe886e8",
   "metadata": {},
   "source": [
    "The URL it chose to visit was \n",
    "\n",
    "```\n",
    "https://pitchfork.com/api/v2/search/?genre=rap&types=reviews&sort=publishdate%20asc&size=1&rating_from=0.0\n",
    "```\n",
    "\n",
    "It adjusted the genre list, the publish date, and decided it only needed a single result! That seems pretty remarkable to me, and the result of an album from 1999 also seems reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43892230",
   "metadata": {},
   "source": [
    "# Implicit documentation\n",
    "\n",
    "While the explicit documentation above is pretty fantastic, **it also might be a waste of time.** Think about it: if ChatGPT generates a new URL by reading the documentation it created by reading the single URL...\n",
    "\n",
    "```{mermaid}\n",
    "flowchart LR\n",
    "  A[URL] --> B[Documentation]\n",
    "  B --> C[New URL]\n",
    "```\n",
    "\n",
    "...why can't we just cut out the middleman? Can't we just say, \"here's a sample URL, figure out the new one?\"\n",
    "\n",
    "```{mermaid}\n",
    "flowchart LR\n",
    "  A[URL] -.- B[Documentation]\n",
    "  B -.- C[New URL]\n",
    "  A ==> C\n",
    "```\n",
    "\n",
    "The documentation isn't providing anything it doesn't know already, so it seems reasonable, right? Let's try it now! Now we're going to create **implicit docs**, which briefly describe the existence of the API and give a sample endpoint. Instead of all that detail, it's just the one URL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d5d4fe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "implicit_docs = \"\"\"\n",
    "Pitchfork has an API with a sample endpoint at https://pitchfork.com/api/v2/search/?genre=experimental&genre=global&genre=jazz&genre=metal&genre=pop&genre=rap&genre=rock&types=reviews&sort=publishdate%20desc%2Cposition%20asc&size=5&start=0&rating_from=0.0\n",
    "\"\"\"\n",
    "\n",
    "implicit_chain = APIChain.from_llm_and_api_docs(llm, implicit_docs, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d54fd0b",
   "metadata": {},
   "source": [
    "**What are you expecting?** Let's give it a shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c3cd1d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new APIChain chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mhttps://pitchfork.com/api/v2/search/?genre=rap&types=reviews&sort=publishdate%20asc&size=1&start=0&rating_from=0.0\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m{\"count\":4253,\"previous\":null,\"next\":null,\"results\":{\"category\":null,\"list\":[{\"tombstone\":{\"bnm\":false,\"bnr\":false,\"albums\":[{\"id\":\"5929c3a7eb335119a49ed773\",\"album\":{\"artists\":[{\"id\":\"592994259d034d5c69bf1739\",\"display_name\":\"Roots Manuva\",\"url\":\"/artists/2672-roots-manuva/\",\"genres\":[{\"display_name\":\"Electronic\",\"slug\":\"electronic\"},{\"display_name\":\"Jazz\",\"slug\":\"jazz\"},{\"display_name\":\"Rap\",\"slug\":\"rap\"}],\"slug\":\"592994259d034d5c69bf1739\",\"photos\":{\"tout\":{\"width\":300,\"height\":300,\"credit\":\"\",\"caption\":\"\",\"altText\":\"Image may contain: Face, Human, Person, Roots Manuva, Head, Photo, Portrait, and Photography\",\"modelName\":\"photo\",\"title\":\"Roots Manuva artist image\",\"sizes\":{\"sm\":\"https://media.pitchfork.com/photos/59299426c0084474cd0bec29/1:1/w_150/3d81e0d6.jpg\",\"m\":\"https://media.pitchfork.com/photos/59299426c0084474cd0bec29/1:1/w_300/3d81e0d6.jpg\"}},\"lede\":false,\"social\":false}}],\"display_name\":\"Brand New Secondhand\",\"labels\":[{\"id\":\"592608737fd06e5349102fdb\",\"name\":\"Ninja Tune\",\"display_name\":\"Ninja Tune\"},{\"id\":\"59260899c31f3f3472b1d6cc\",\"name\":\"Big Dada\",\"display_name\":\"Big Dada\"}],\"release_year\":1999,\"photos\":{\"tout\":{\"width\":150,\"height\":150,\"credit\":\"\",\"caption\":\"\",\"altText\":\"Image may contain: Display, Screen, Electronics, Monitor, Television, and TV\",\"title\":\"Brand New Secondhand cover art\",\"sizes\":{\"list\":\"https://media.pitchfork.com/photos/5929c3a7c0084474cd0c3506/1:1/w_160/c23e052b.gif\",\"standard\":\"https://media.pitchfork.com/photos/5929c3a7c0084474cd0c3506/1:1/w_600/c23e052b.gif\",\"homepageSmall\":\"https://media.pitchfork.com/photos/5929c3a7c0084474cd0c3506/1:1/w_55/c23e052b.gif\",\"homepageLarge\":\"https://media.pitchfork.com/photos/5929c3a7c0084474cd0c3506/1:1/w_320/c23e052b.gif\"}},\"lede\":false,\"social\":false}},\"rating\":{\"display_rating\":\"9.5\",\"rating\":\"9.5\",\"bnm\":false,\"bnr\":false},\"labels_and_years\":[{\"labels\":[{\"id\":\"592608737fd06e5349102fdb\",\"name\":\"Ninja Tune\",\"display_name\":\"Ninja Tune\"},{\"id\":\"59260899c31f3f3472b1d6cc\",\"name\":\"Big Dada\",\"display_name\":\"Big Dada\"}],\"year\":1999}]}]},\"artists\":[{\"id\":\"592994259d034d5c69bf1739\",\"display_name\":\"Roots Manuva\",\"url\":\"/artists/2672-roots-manuva/\",\"genres\":[{\"display_name\":\"Electronic\",\"slug\":\"electronic\"},{\"display_name\":\"Jazz\",\"slug\":\"jazz\"},{\"display_name\":\"Rap\",\"slug\":\"rap\"}],\"slug\":\"592994259d034d5c69bf1739\",\"photos\":{\"tout\":{\"width\":300,\"height\":300,\"credit\":\"\",\"caption\":\"\",\"altText\":\"Image may contain: Face, Human, Person, Roots Manuva, Head, Photo, Portrait, and Photography\",\"modelName\":\"photo\",\"title\":\"Roots Manuva artist image\",\"sizes\":{\"sm\":\"https://media.pitchfork.com/photos/59299426c0084474cd0bec29/1:1/w_150/3d81e0d6.jpg\",\"m\":\"https://media.pitchfork.com/photos/59299426c0084474cd0bec29/1:1/w_300/3d81e0d6.jpg\"}},\"lede\":false,\"social\":false}}],\"genres\":[{\"display_name\":\"Electronic\",\"slug\":\"electronic\"},{\"display_name\":\"Jazz\",\"slug\":\"jazz\"},{\"display_name\":\"Rap\",\"slug\":\"rap\"}],\"channel\":\"\",\"subChannel\":\"\",\"position\":6,\"id\":\"5929e2b6c0084474cd0c4dc2\",\"url\":\"/reviews/albums/5099-brand-new-secondhand/\",\"contentType\":\"albumreview\",\"title\":\"<em>Brand New Secondhand</em>\",\"seoTitle\":\"Brand New Secondhand\",\"socialTitle\":\"Roots Manuva: Brand New Secondhand\",\"promoTitle\":\"Brand New Secondhand\",\"authors\":[{\"id\":\"592604af17cea934e4daf5f4\",\"name\":\"Paul Cooper\",\"title\":\"Contributor\",\"url\":\"/staff/paul-cooper/\",\"slug\":\"staff/paul-cooper\"}],\"pubDate\":\"1999-03-23T06:00:06.000Z\",\"timestamp\":922168806000,\"modifiedAt\":\"2022-03-31T08:47:24.426Z\",\"dek\":\"<p>For politcially unaware, socially unconscious, ethically moribund pop culture vultures, there's no bigger disappointment than UK hip-hop. In the ...</p>\\n\",\"seoDescription\":\"For politcially unaware, socially unconscious, ethically moribund pop culture vultures, there's no bigger disappointment than UK hip-hop. In the ...\",\"promoDescription\":\"<p>For politcially unaware, socially unconscious, ethically moribund pop culture vultures, there's no bigger disappointment than UK hip-hop. In the ...</p>\\n\",\"socialDescription\":\"For politcially unaware, socially unconscious, ethically moribund pop culture vultures, there's no bigger disappointment than UK hip-hop. In the ...\",\"privateTags\":[\"_dj_id:5099\",\"_original_author_id:95\"],\"tags\":[]}]}}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The first rap album reviewed by Pitchfork was \"Brand New Secondhand\" by Roots Manuva, published on March 23, 1999, with a rating of 9.5. The API call used to retrieve this information was: https://pitchfork.com/api/v2/search/?genre=rap&types=reviews&sort=publishdate%20asc&size=1&start=0&rating_from=0.0.'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implicit_chain.run(\"What was the first rap album reviewed by pitchfork?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba18e29",
   "metadata": {},
   "source": [
    "That's an A+ perfect response, with a heck of a lot less work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07f2503",
   "metadata": {},
   "source": [
    "# Summary and differences\n",
    "\n",
    "There are two major ways the explicit and implicit approaches differ: success rates and costs.\n",
    "\n",
    "## Success rates\n",
    "\n",
    "Believe it or not, **the implicit approach has a much higher success rate!**\n",
    "\n",
    "In writing this piece, I've had to tweak the prompt that generates the explicit documentation again and again. ChatGPT seems to go out of its way to lie about the API, and not even in subtle ways:\n",
    "\n",
    "* It loves to introduce new, non-existent features\n",
    "* Turn the `genre=rap&genre=folk` parameter into various flavors of `genre=rap,folk`, and just generally sacrifices the reality of the API for \n",
    "* Invent lower and upper bounds for page sizes and ratings\n",
    "\n",
    "While these might be good architectural changes or useful new features, they absolutely aren't implied by the original URL! Without adding a push to be conservative to the prompt, we end up with docs that are completely misleading.\n",
    "\n",
    "When you take the misleading documentation and feed it to the `APIChain` prompt, it winds up screwing up the request a large portion of the time. Overall I've found it breaks about a third of the time on the explicitly-documented example!\n",
    "\n",
    "On the other hand, explicit documentation allows you to clean up and customize the docs. If you find out the maximum and minimum page size, you're free to add it! If other genres get released or removed you're more than welcome to edit the list.\n",
    "\n",
    "But if you're lazy, and just looking for a shortcut? **Implicit docs always peform better**.\n",
    "\n",
    "\n",
    "## Costs\n",
    "\n",
    "While we're all very excited about using the various OpenAI APIs, **they do cost money.** Yes, `GPT-3.5-turbo` is remarkably inexpensive compared to its peers, but we aren't here to waste money! If we can keep the prompt smaller our queries cost less, and saving money is the second-quickest route to happiness.\n",
    "\n",
    "Let's use LangChain's `get_openai_callback` to examine the token count and cost of our explicit vs implicit requests. Note that we're using `verbose=False` here to reduce clutter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ff0a2b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The first rap album reviewed by Pitchfork was Roots Manuva's \"Brand New Secondhand\" released in 1999, with a review published on March 23, 1999, with a rating of 9.5.\n",
      "Total Tokens: 3058\n",
      "Prompt Tokens: 2970\n",
      "Completion Tokens: 88\n",
      "Total Cost (USD): $0.006116\n"
     ]
    }
   ],
   "source": [
    "explicit_chain = APIChain.from_llm_and_api_docs(llm, explicit_docs, verbose=False)\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    response = explicit_chain.run(\"What was the first rap album reviewed by pitchfork?\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Total Cost (USD): ${cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5eb7d2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The first rap album reviewed by Pitchfork was \"Brand New Secondhand\" by Roots Manuva, with a rating of 9.5. The review was written by Paul Cooper and was published on March 23, 1999.\n",
      "Total Tokens: 1811\n",
      "Prompt Tokens: 1722\n",
      "Completion Tokens: 89\n",
      "Total Cost (USD): $0.0036220000000000002\n"
     ]
    }
   ],
   "source": [
    "implicit_chain = APIChain.from_llm_and_api_docs(llm, implicit_docs, verbose=False)\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    response = implicit_chain.run(\"What was the first rap album reviewed by pitchfork?\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Total Cost (USD): ${cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c9033e",
   "metadata": {},
   "source": [
    "Along with being consistent less correct, **the explicit chain costs around twice as much!** Just above 0.6 cents for explicit compared to `0.36` for implicit. Depending on how wordy GPT decides to be, some of my tests have seen it up to tree times as much!\n",
    "\n",
    "The wildest part about this large difference is that both queries almost always making the *same* API response, which I assume would take up the bulk of the tokens (secret fact: Pitchfork's API is so wordy I changed the example to `size=5` so that it would fit in the GPT-3.5-turbo context window).\n",
    "\n",
    "## The takeaway\n",
    "\n",
    "Unless you enjoy editing or spending money, it looks like *less is more*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a144bf59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
